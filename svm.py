# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oexh5FcJfhnr4XzFobwL4QRr50qPyRKW
"""

from google.colab import drive
drive.mount('/content/gdrive')

!tar -C "/content" -xf "/content/gdrive/My Drive/pattern/UTKFace.tar.gz"

!tar -C "/content" -xf "/content/gdrive/My Drive/pattern/crop_part1.tar.gz"

!pip install mahotas

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.utils import shuffle
from imutils import paths
import mahotas
from sklearn import preprocessing
from sklearn import metrics
from sklearn import svm


import matplotlib.pyplot as plt 
# %matplotlib inline

import os
import numpy as np
import cv2
import pylab as pl
import seaborn as sns

def fd_hu_moments(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    feature = cv2.HuMoments(cv2.moments(image)).flatten()
    return feature

def fd_haralick(image,size=(60,60)):    # convert the image to grayscale
    image = cv2.resize(image, size)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # compute the haralick texture feature vector
    haralick = mahotas.features.haralick(gray).mean(axis=0)
    
    return haralick

def fd_histogram(image, mask=None,bins=(8, 8, 8)):
    # convert the image to HSV color-space
    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    # compute the color histogram
    hist  = cv2.calcHist([image], [0, 1, 2], None,bins, [0, 256, 0, 256, 0, 256])
    # normalize the histogram
    cv2.normalize(hist, hist)
    hist.flatten()

def image_to_feature_vector(image, size=(50, 50)):
  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
  return cv2.resize(image, size).flatten()

# def extract_color_histogram(image, bins=(8, 8, 8)):
# 	hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
# 	hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,
# 		[0, 180, 0, 256, 0, 256])
  
# 	hist = cv2.normalize(hist,hist)
 
# 	return hist.flatten()

imagePaths=[]
imagePaths+=(list(paths.list_images("/content/UTKFace")))
    
print(len(imagePaths))

rawImages = []
labels = []
features =[] 
for (i, imagePath) in enumerate(imagePaths):
    image = cv2.imread(imagePath)
    #global_feature = np.hstack([fd_histogram(image), fd_haralick(image), fd_hu_moments(image)])
    
    
    label = imagePath.split(os.path.sep)[-1].split("_")[0]
    label =int(label)
    
    pixels = image_to_feature_vector(image)
    #hist = extract_color_histogram(image) 

    rawImages.append(pixels)
    #features.append(global_feature)
    
    if label >0 and label <=10: labels.append(1)
    elif label >10 and label<=20: labels.append(2)
    elif label >20 and label<=30: labels.append(3)
    elif label >30 and label<=40: labels.append(4)
    elif label >40 and label<=50: labels.append(5)
    elif label >50 and label<=60: labels.append(6)
    elif label >60 and label<=70: labels.append(7)
    elif label >70 and label<=80: labels.append(8)
    elif label >90 and label<=100: labels.append(9)  
    elif label >100 and label<=110: labels.append(10)
    else: labels.append(11)
    
    if i > 0 and i % 1000 == 0:
        print("[INFO] processed {}/{}".format(i, len(imagePaths)))

#Normalize The feature vectors...
#scaler = MinMaxScaler(feature_range=(0, 1))
#features = scaler.fit_transform(features)

rawImages = np.array(rawImages)
labels = np.array(labels)
#features = np.array(features)

print("[INFO] pixels matrix: {:.2f}MB".format(
	rawImages.nbytes / (1024 * 1000.0)))
# print("[INFO] features matrix: {:.2f}MB".format(
# 	features.nbytes / (1024 * 1000.0)))

(X_train, X_test , y_train, y_test) = train_test_split(rawImages, labels, test_size=0.25, random_state=42)
#(X_trainF,X_testF, y_trainF, y_testF) = train_test_split(features, labels, test_size=0.25, random_state=42)

print("Dimension of Train set",X_train.shape)
print("Dimension of Test set",X_test.shape,"\n")

"""# histogram Feature accuracy: 35.37% 
# C=100,kerneal rbf,gamma 0.001
```
param_grid = [
  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},
 ]
```


# Pixels Accuracy : 72.01% 
# C=500,gamma=0.00001,kernel='linear',random_state=0
"""

# param_grid = [
#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},
#  ]
#svc = svm.SVC(C=1,kernel = 'linear')

clf = svm.SVC(C=500,gamma=0.00001,kernel='linear',random_state=0)

#clf = GridSearchCV(svc, param_grid)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print("Classification report for - \n{}\n".format(clf))
      
acc=metrics.accuracy_score(y_testF, y_pred)

print("[INFO] histogram accuracy: {:.2f}%".format(acc * 100))